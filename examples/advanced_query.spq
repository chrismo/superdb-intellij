-- Advanced SuperSQL Query Examples
-- Demonstrates complex features and patterns

/*
 * Multi-line block comment
 * explaining the purpose of this query file
 */

-- Pragma for query hints
pragma optimization = "aggressive"

-- Complex operator declaration
op filter_and_enrich items:
    (
        items
        | where is_valid(this)
        | put enriched := fetch_metadata(this.id)
    )

-- Query declaration with let
let active_sessions = (
    FROM sessions
    | where end_time is null
    | where start_time >= 2024-01-01T00:00:00Z
)

-- Using the declared query
FROM active_sessions
| count() by user_id
| top 10

-- Complex JOIN with multiple tables
SELECT
    o.order_id,
    c.customer_name,
    p.product_name,
    o.quantity,
    o.unit_price * o.quantity AS line_total
FROM orders o
INNER JOIN customers c ON o.customer_id == c.id
LEFT JOIN products p ON o.product_id == p.id
WHERE o.status != "cancelled"
  AND o.order_date BETWEEN 2024-01-01 AND 2024-12-31
ORDER BY o.order_date DESC, line_total DESC
LIMIT 1000 OFFSET 100

-- Subquery in FROM clause
SELECT
    region,
    avg(total_sales) AS avg_regional_sales
FROM (
    SELECT
        region,
        customer_id,
        sum(amount) AS total_sales
    FROM sales
    GROUP BY region, customer_id
) AS customer_totals
GROUP BY region

-- Array subquery
SELECT
    user_id,
    [SELECT order_id FROM orders WHERE orders.user_id == users.user_id] AS order_ids
FROM users

-- EXISTS subquery
SELECT *
FROM customers c
WHERE EXISTS (
    FROM orders o
    | where o.customer_id == c.id
    | where o.amount > 1000
)

-- Complex CASE expression
SELECT
    product_id,
    CASE
        WHEN inventory > 100 THEN "high"
        WHEN inventory BETWEEN 20 AND 100 THEN "medium"
        WHEN inventory > 0 THEN "low"
        ELSE "out_of_stock"
    END AS stock_level,
    CASE category
        WHEN "electronics" THEN tax_rate * 1.2
        WHEN "food" THEN tax_rate * 0.5
        ELSE tax_rate
    END AS adjusted_tax
FROM products

-- Window function simulation with aggregation
FROM sales
| sort date
| put running_total := sum(amount) by customer_id
| put daily_rank := count() by date

-- Explode array into rows
FROM events
| explode tags by string as tag
| count() by tag
| sort -r count

-- Unnest nested structures
FROM documents
| unnest sections into (
    put section_title := this.title
    | put section_content := this.body
  )

-- Merge sorted streams
FROM stream_a
| merge timestamp
| from stream_b

-- Complex record construction with spread
FROM users
| put profile := {
    ...user_info,
    computed_field: calculate_score(this),
    tags: [...existing_tags, "processed"],
    metadata: |{
        "source": "pipeline",
        "version": "1.0"
    }|
  }

-- Type union handling
type Response = {
    status: int32,
    body: string | null | error(string)
}

-- Error type usage
type SafeResult = int64 | error({
    code: int32,
    message: string
})

-- Enum type
type Status = enum("pending", "active", "completed", "cancelled")

-- Map type operations
SELECT
    user_id,
    |{
        "first": scores[0],
        "last": scores[-1],
        "avg": avg(scores)
    }| AS score_summary
FROM user_scores

-- Formatted strings (f-strings)
FROM logs
| put formatted := f"User {user_id} performed {action} at {timestamp}"

-- Raw strings for regex patterns
FROM logs
| search r"\d{4}-\d{2}-\d{2}"
| put extracted := grok(message, r"(?P<ip>\d+\.\d+\.\d+\.\d+)\s+(?P<user>\w+)")

-- EXTRACT function
SELECT
    EXTRACT(year FROM timestamp) AS year,
    EXTRACT(month FROM timestamp) AS month,
    EXTRACT(day FROM timestamp) AS day,
    EXTRACT(hour FROM timestamp) AS hour
FROM events

-- SUBSTRING function
SELECT
    SUBSTRING(name FROM 1 FOR 10) AS short_name,
    SUBSTRING(email FROM position('@' IN email) + 1) AS domain
FROM users

-- VALUES clause
INSERT INTO log_entries
VALUES
    (1, 'info', 'System started', 2024-01-01T00:00:00Z),
    (2, 'warning', 'High memory usage', 2024-01-01T00:01:00Z),
    (3, 'error', 'Connection failed', 2024-01-01T00:02:00Z)

-- Debug operator for troubleshooting
FROM events
| debug this
| where type == "click"
| debug count()
| count() by page_id

-- Output to named sink
FROM processed_events
| output analytics_stream

-- Load into pool with commit reference
load events_pool @main:events
